{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e172ad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bb46a8",
   "metadata": {},
   "source": [
    "untuk model llm yang akan digunakan masih sama yaitu ollama3:8b namun model akan ditarik atau digunakan melalui interface langhcain sehingga bisa menjadi object class yang bisa dimasukkan kedalam ConversationsChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5ec5fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a/Programming/Langchain-Project/my-env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df6e5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/05/16tm42991snf6c27rs7nssdh0000gn/T/ipykernel_8906/187133202.py:1: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the `langchain-ollama package and should be used instead. To use it run `pip install -U `langchain-ollama` and import as `from `langchain_ollama import ChatOllama``.\n",
      "  llm_local = ChatOllama(\n"
     ]
    }
   ],
   "source": [
    "llm_local = ChatOllama(\n",
    "    model=\"llama3:8b\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead51547",
   "metadata": {},
   "source": [
    "mencoba menggunakan buffermemory dari langchain agar agent atau model LLM bisa mengingat percakapan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e2198e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains import ConversationChain\n",
    "from langchain_classic.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa2d37ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/05/16tm42991snf6c27rs7nssdh0000gn/T/ipykernel_8906/995385594.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90b0b9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/05/16tm42991snf6c27rs7nssdh0000gn/T/ipykernel_8906/264170612.py:1: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use `langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm_local,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b565d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: hallo, kamu tau namaku siapa?\n",
      "AI: Haloo! I'm happy to chat with you! As for your question, I don't have any information about your name. I'm a large language model, I don't have personal interactions or memories, so I wouldn't know your name unless you tell me. But please feel free to introduce yourself, and I'll do my best to learn more about you!\n",
      "Human: hi, my name is Romi\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Nice to meet you, Romi! I'm glad you introduced yourself. As a large language model, I can process and store information about individuals, but it's not like I have a personal memory or database that keeps track of people. Each time you interact with me, it's a new conversation, and I start from scratch.\\n\\nBy the way, did you know that my training data includes over 45 billion parameters? That's a lot of information! And I can process natural language inputs at speeds of up to 3.5 gigahertz. But enough about me; what brings you here today, Romi?\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"hi, my name is Romi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab3871b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: hallo, kamu tau namaku siapa?\n",
      "AI: Haloo! I'm happy to chat with you! As for your question, I don't have any information about your name. I'm a large language model, I don't have personal interactions or memories, so I wouldn't know your name unless you tell me. But please feel free to introduce yourself, and I'll do my best to learn more about you!\n",
      "Human: hi, my name is Romi\n",
      "AI: Nice to meet you, Romi! I'm glad you introduced yourself. As a large language model, I can process and store information about individuals, but it's not like I have a personal memory or database that keeps track of people. Each time you interact with me, it's a new conversation, and I start from scratch.\n",
      "\n",
      "By the way, did you know that my training data includes over 45 billion parameters? That's a lot of information! And I can process natural language inputs at speeds of up to 3.5 gigahertz. But enough about me; what brings you here today, Romi?\n",
      "Human: hallo, kamu tau namaku siapa?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Romi, we already had this conversation earlier! You introduced yourself as Romi, and I'm happy to chat with you again. Since we're starting a new conversation, I don't need to ask your name again. How about we dive into something new? What's been on your mind lately, or is there something specific you'd like to talk about or learn?\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"hallo, kamu tau namaku siapa?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2377f384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
