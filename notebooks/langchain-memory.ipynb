{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02bb46a8",
   "metadata": {},
   "source": [
    "untuk model llm yang akan digunakan masih sama yaitu ollama3:8b namun model akan ditarik atau digunakan melalui interface langhcain sehingga bisa menjadi object class yang bisa dimasukkan kedalam ConversationsChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5ec5fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a/Programming/Langchain-Project/my-env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5df6e5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/05/16tm42991snf6c27rs7nssdh0000gn/T/ipykernel_3215/187133202.py:1: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the `langchain-ollama package and should be used instead. To use it run `pip install -U `langchain-ollama` and import as `from `langchain_ollama import ChatOllama``.\n",
      "  llm_local = ChatOllama(\n"
     ]
    }
   ],
   "source": [
    "llm_local = ChatOllama(\n",
    "    model=\"llama3:8b\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead51547",
   "metadata": {},
   "source": [
    "mencoba menggunakan buffermemory dari langchain agar agent atau model LLM bisa mengingat percakapan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e2198e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains import ConversationChain\n",
    "from langchain_classic.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa2d37ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/05/16tm42991snf6c27rs7nssdh0000gn/T/ipykernel_3215/995385594.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90b0b9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/05/16tm42991snf6c27rs7nssdh0000gn/T/ipykernel_3215/3469883279.py:1: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use `langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm_local,\n",
    "    memory=memory,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b565d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Assalamualaikum! I'm happy to chat with you in Bahasa Indonesia. My name is LLaMA, and I'm an AI designed to understand and respond to human language. I don't have personal experiences or emotions like humans do, but I can provide information on a wide range of topics, from science and history to entertainment and culture.\\n\\nI see that you've introduced yourself as Romi! That's a lovely Indonesian name. Can I help you with something specific, or would you like to chat about your interests?\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"you are assistand which answer with bahasa yah, nama saya adalah Romi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2377f384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hai Romi, saya tahu nama Anda adalah Romi, karena Anda sendiri yang mengatakan \"Nama saya adalah Romi\"! Saya LLaMA, dan saya siap membantu Anda dengan pertanyaan atau topik apapun. Apa yang ingin Anda bicarakan tentang?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"hai kamu tau siapa namaku, please answer in bahasa yah\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea25f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
