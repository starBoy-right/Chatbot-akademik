{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "860acc2c",
   "metadata": {},
   "source": [
    "langsmith digunakan untuk tracking block chain yang digunakan pada langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9770737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94de4fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80f31796",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGSMITH_TRACING = os.getenv(\"LANGSMITH_TRACING\")\n",
    "LANGSMITH_API_KEY = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "LANGSMITH_PROJECT = os.getenv(\"LANGSMITH_PROJECT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2479eb68",
   "metadata": {},
   "source": [
    "1. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9855e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a/Programming/Langchain-Project/my-env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2314e17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/05/16tm42991snf6c27rs7nssdh0000gn/T/ipykernel_13917/85654660.py:1: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the `langchain-ollama package and should be used instead. To use it run `pip install -U `langchain-ollama` and import as `from `langchain_ollama import ChatOllama``.\n",
      "  llm_model = ChatOllama(\n"
     ]
    }
   ],
   "source": [
    "llm_model = ChatOllama(\n",
    "    model='mistral-openorca:7b-q4_0',\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e88361",
   "metadata": {},
   "source": [
    "2. prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4035eaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5ed49a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Kamu adalah asisten chatbot yang membantu. \n",
    "    Tugasmu adalah menjawab pertanyaan berikut secara langsung dalam Bahasa Indonesia. \n",
    "    Meskipun pertanyaan diberikan dalam Bahasa Inggris atau bahasa lain, kamu WAJIB menjawabnya dalam Bahasa Indonesia.\n",
    "    \n",
    "    Pertanyaan: {input}\n",
    "    Jawaban:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f9e1ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface_user = \"bisa jelaskan apa itu jokowi dodo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a73a5956",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm_model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8f6154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Jokowi Dodo adalah sebuah film animasi yang merupakan adaptasi dari cerita tradisional Indonesia tentang perjuangan seorang burung yang bernama Joko, atau lebih dikenal dengan nama \"Jokowi\" dalam bahasa Indonesia. Di dalam cerita ini, Jokowi berjuang untuk mencari kembali teman-teman yang tersingir oleh satu burung pemburu yang bernama Dodo. Film ini didirikan untuk memberikan pesan tentang keberani, semangat, dan kesahastraan dalam mengatasi permasalahan yang disadari.\n"
     ]
    }
   ],
   "source": [
    "respone = chain.invoke({\"input\": interface_user})\n",
    "print(respone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57115a6",
   "metadata": {},
   "source": [
    "3. Embedding model -> digunakan untuk mengubah external data ke dalam bentuk vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07977f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# memanggil Indobert dari transformer\n",
    "from transformers import BertTokenizer, AutoModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"Indobenchmark/indobert-base-p1\")\n",
    "model = AutoModel.from_pretrained(\"indobenchmark/indobert-base-p1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6bcf1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat class model embdding\n",
    "from typing import List \n",
    "from langchain_core.embeddings import Embeddings\n",
    "import torch\n",
    "\n",
    "class IndoBertEmbeddings(Embeddings):\n",
    "    def __init__(self, model_name=\"indobenchmark/indobert-base-p1\"):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.model.eval()\n",
    "\n",
    "\n",
    "    def _generate_embedding(self, text: str) -> List[float]:\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "\n",
    "        # polling token menjadi satu vector kalimat\n",
    "        token_embeddings = outputs.last_hidden_state\n",
    "\n",
    "        # melakukan mean polling\n",
    "        sentence_embeddings = token_embeddings.mean(dim=1)\n",
    "\n",
    "        # konversi ke list python\n",
    "        return sentence_embeddings.squeeze().tolist()\n",
    "    \n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return [self._generate_embedding(text) for text in texts]\n",
    "    \n",
    "\n",
    "    # metode untuk pencarian query pada chroma \n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self._generate_embedding(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c31fcbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = IndoBertEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd3b7f6",
   "metadata": {},
   "source": [
    "4. Vector store (kita akan menggunakan chromadb yang sebelumnya telah disetup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f76a843",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6883b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectore_store = Chroma(\n",
    "    collection_name=\"chroma-with-langchain\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"../Langchain-Project/notebooks/chroma_langchain_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04f5c05",
   "metadata": {},
   "source": [
    "5. Indexing (Load -> split -> store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbef895f",
   "metadata": {},
   "source": [
    "![image.png](https://mintcdn.com/langchain-5e9cc07a/I6RpA28iE233vhYX/images/rag_indexing.png?w=840&fit=max&auto=format&n=I6RpA28iE233vhYX&q=85&s=1838328a870c7353c42bf1cc2290a779)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2533a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a/Programming/Langchain-Project/my-env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# load documents dan kita ubah kedalam bentuk document standart langchain yaitu document object \n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d39f33eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post_header\", \"post-content\"))\n",
    "# loader = WebBaseLoader(\n",
    "#     web_path=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),  # data diambil dari blognya lilianweng\n",
    "#     bs_kwargs={\"parse_only\": bs4_strainer}\n",
    "# )\n",
    "\n",
    "# ngambil data dari web sttnf\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post_header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_path=(\"https://nurulfikri.ac.id/\",),  # data diambil dari blognya lilianweng\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer}\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef918557",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ae8d9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total character: 42964\n"
     ]
    }
   ],
   "source": [
    "assert len(docs) == 1\n",
    "print(f\"Total character: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53996686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large t\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:600])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0db3a8",
   "metadata": {},
   "source": [
    "Selanjutnya adalah splitting document\n",
    "Karena document yang telah di load itu sangat panjang, sekita 42K, model LLM akan kesulitan menjadikan ini sebagai input. Maka dari itu kita bagi ini menjadi beberapa chuncks atau potongan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6478ce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitter \n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db60c777",
   "metadata": {},
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9792368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, #chunk size (characters)\n",
    "    chunk_overlap=200, # overlap (Characters)\n",
    "    add_start_index=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72d4eb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8be276a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split blog post into 63 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "print(f\"split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "60789e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='LLM Powered Autonomous Agents\n",
      "    Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory' metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 7}\n"
     ]
    }
   ],
   "source": [
    "print(all_splits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a3269541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing document kedalam chromaDB\n",
    "document_ids = vectore_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ace1ee29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7f0dba64-9df4-4f98-b236-e65a05ee59cb', '65d37f22-25e1-4497-8b0f-9af2842c51e2', '0ffa8ee9-1029-429a-ac30-0848f626c9d7']\n"
     ]
    }
   ],
   "source": [
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "72e363d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is task decomposition?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "78ed9d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_ = vectore_store.similarity_search(query=query, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ffe2f46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You always add a comment briefly describing the purpose of the function definition.\n",
      "You try to add comments explaining very complex bits of logic.\n",
      "You always follow the best practices for the requested languages in terms of describing the code written as a defined\n",
      "package/project.\n",
      "Python toolbelt preferences:\n",
      "Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\n",
      "\n",
      "The system comprises of 4 stages:\n",
      "(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\n",
      "Instruction:\n",
      "(4) Response generation: LLM receives the execution results and provides summarized results to users.\n",
      "To put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It relies on a long context window to communicate over complicated task content; (3) Stability improvement of LLM outputs and external model services.\n"
     ]
    }
   ],
   "source": [
    "for doc in testing_:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb0c918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
