{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "860acc2c",
   "metadata": {},
   "source": [
    "langsmith digunakan untuk tracking block chain yang digunakan pada langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9770737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94de4fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80f31796",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGSMITH_TRACING = os.getenv(\"LANGSMITH_TRACING\")\n",
    "LANGSMITH_API_KEY = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "LANGSMITH_PROJECT = os.getenv(\"LANGSMITH_PROJECT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2479eb68",
   "metadata": {},
   "source": [
    "1. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9855e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a/Programming/Langchain-Project/my-env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2314e17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/05/16tm42991snf6c27rs7nssdh0000gn/T/ipykernel_24845/2586603255.py:1: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the `langchain-ollama package and should be used instead. To use it run `pip install -U `langchain-ollama` and import as `from `langchain_ollama import ChatOllama``.\n",
      "  llm_model = ChatOllama(\n"
     ]
    }
   ],
   "source": [
    "llm_model = ChatOllama(\n",
    "    model='llama3:8b',\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e88361",
   "metadata": {},
   "source": [
    "2. prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4035eaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5ed49a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Kamu adalah asisten chatbot yang membantu. \n",
    "    Tugasmu adalah menjawab pertanyaan berikut secara langsung dalam Bahasa Indonesia. \n",
    "    Meskipun pertanyaan diberikan dalam Bahasa Inggris atau bahasa lain, kamu WAJIB menjawabnya dalam Bahasa Indonesia.\n",
    "    \n",
    "    Pertanyaan: {input}\n",
    "    Jawaban:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f9e1ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface_user = \"apa itu ninjutsu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a73a5956",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm_model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8f6154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ninjutsu adalah seni bela diri tradisional Jepang yang dikembangkan oleh ninja. Istilah \"ninjutsu\" sendiri berarti \"ilmu ninja\". Ninjutsu meliputi berbagai teknik, seperti gerakan tubuh, strategi, dan psikologi, yang digunakan untuk mencapai tujuan tertentu, seperti pengintaian, perang, atau penyelamatan.\n"
     ]
    }
   ],
   "source": [
    "respone = chain.invoke({\"input\": interface_user})\n",
    "print(respone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57115a6",
   "metadata": {},
   "source": [
    "3. Embedding model -> digunakan untuk mengubah external data ke dalam bentuk vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07977f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# memanggil Indobert dari transformer\n",
    "from transformers import BertTokenizer, AutoModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"Indobenchmark/indobert-base-p1\")\n",
    "model = AutoModel.from_pretrained(\"indobenchmark/indobert-base-p1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6bcf1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat class model embdding\n",
    "from typing import List \n",
    "from langchain_core.embeddings import Embeddings\n",
    "import torch\n",
    "\n",
    "class IndoBertEmbeddings(Embeddings):\n",
    "    def __init__(self, model_name=\"indobenchmark/indobert-base-p1\"):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.model.eval()\n",
    "\n",
    "\n",
    "    def _generate_embedding(self, text: str) -> List[float]:\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "\n",
    "        # polling token menjadi satu vector kalimat\n",
    "        token_embeddings = outputs.last_hidden_state\n",
    "\n",
    "        # melakukan mean polling\n",
    "        sentence_embeddings = token_embeddings.mean(dim=1)\n",
    "\n",
    "        # konversi ke list python\n",
    "        return sentence_embeddings.squeeze().tolist()\n",
    "    \n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return [self._generate_embedding(text) for text in texts]\n",
    "    \n",
    "\n",
    "    # metode untuk pencarian query pada chroma \n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self._generate_embedding(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c31fcbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = IndoBertEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd3b7f6",
   "metadata": {},
   "source": [
    "4. Vector store (kita akan menggunakan chromadb yang sebelumnya telah disetup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f76a843",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6883b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectore_store = Chroma(\n",
    "    collection_name=\"chroma-with-langchain\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"../Langchain-Project/notebooks/chroma_langchain_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04f5c05",
   "metadata": {},
   "source": [
    "5. Indexing (Load -> split -> store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbef895f",
   "metadata": {},
   "source": [
    "![image.png](https://mintcdn.com/langchain-5e9cc07a/I6RpA28iE233vhYX/images/rag_indexing.png?w=840&fit=max&auto=format&n=I6RpA28iE233vhYX&q=85&s=1838328a870c7353c42bf1cc2290a779)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2533a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# load documents dan kita ubah kedalam bentuk document standart langchain yaitu document object \n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39f33eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post_header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_path=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),  # data diambil dari blognya lilianweng\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef918557",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ae8d9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total character: 42964\n"
     ]
    }
   ],
   "source": [
    "assert len(docs) == 1\n",
    "print(f\"Total character: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53996686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agentâ€™s brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large t\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:600])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
